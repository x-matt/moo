## 转正申请
### 组别（算法集成组）
1. EIS - [J10][MTK]平台（5月下旬～现在）
    1. MTK 基础框架学习
        1. 按照对高通框架的学习思路，对MTK的Open，Config，Process等流程进行了整理学习
        2. 了解在MTK平台算法集成的流程，过程中需要修改的文件
    2. 三方EIS-VIDHANCE算法集成框架学习
        1. 跟导师一起进到项目中，将解Bug与看代码相结合，熟悉EIS算法的调用接口
        2. 项目过程中，针对系列Bug，学习掌握了调节画质效果的一系列参数
    3. 预言MTK提供的EIS
        1. 三方EIS效果不够好（画质差，画面不跟手），对MTK-EIS进行预言工作
        2. 调通MTK-EIS，将代码逻辑在Hal层的逻辑写死，还未与APP端配合调试，当前正由Tuning进行画质调校
    4. 学习阶段解决了7个Jira，提交了30笔代码，总结了8篇Wiki，配合导师完成对EIS输入图片尺寸的修改
2. Hal层框架 - [J11][Qcom]平台（4月初～5月中旬）
    1. 学习Hal层相关代码，结合Log，了解每个模块的入口和出口，学习各个模块在整个框架中的担任的角色
    2. 绘制时序图，将Camera的Open，Config，Process三个过程的函数串联的过程绘制出来，结合log，可以快速定位问题点
    3. 阅读高通文档，了解Hal层各个子模块的作用，usecase、feature、pipeline，通过对模块的封装，提高调用的灵活度
    4. 学习阶段解决了1个Jira，提交了2笔代码，总结了16篇Wiki
3. 基础知识的学习与集团培训（3月下旬 ～ 8月下旬）
    1. 相机硬件组成
    2. 相机成像原理及基础的参数概念
    3. 工具
        1. log开关与等级的控制，针对不同模块的log打开方式和等级调节方式进行了整理
        2. trace的使用，配合分析相机性能相关的问题
        3. dump，可输出过程中的buffer，定位问题点，针对MTK平台，对各个模块的dump方法进行了整理
    4. 学习网络课程，了解手机部其他部门的工作内容
    5. 通过集团应届生培训，了解了公司的企业文化，学习了基础的职业规范

### 收获
1. 通过集团高管的培训，了解了企业创业初期的艰辛，我们作为应届生，应当把握好机会，克服眼高手低的心理，踏踏实实把手头的工作做好
2. 工作中应该注重平时的记录和周期性的总结，一方面可以避免遗忘，另一方面可以协助构建知识脉络框架，更好地了解整个知识体系
3. 在日常的工作过程中，需要尽量提高效率，注重沟通的质量，注重对工具使用。例如解Bug时，应该针对问题，提供尽量全面的log & dump资料
4. 遇到问题时，多学会沟通，多学会请教，很多时候问题可能是别人遇到过的，尤其是在共基线的项目中


战功
1. EIS算法集成相关
    1. [K10/K10A/K11R][MTK]平台
        1. 完成VIDHANCE-WPE-EIS的预研，并顺利在K10项目上落地
            - 相较于原先运行在GPU的版本，运行在WPE（Wapping Engine）上能够节省约30mA的功耗
            - 防抖效果上两个版本表现基本一致
            - 过程中主要问题：
                1. 完成针对WPE两种数据流模式的适配 StandAlone Mode & DirectLink Mode，考虑到DirectLink模式会空跑一个MDP，最终采用了StandAlone模式
                2. 解决WPE模块的输出图裁切的边沿图片有拖影的问题，通过对比分析MTK-Bokeh(也是跑在WPE上)的输出接口，确认了VIDHANCE没有调用相关的Output接口，导致输出buffer异常
        2. 打通VIDHANCE-EIS的YuvPlugin
            1. 原因：完成AIIE算法跑在EIS-Node后面的需求，当前使用的DivisionPlugin是两路流输出，只能接在TPI的最后面
            2. 优势：让EIS运行在最前面，能够让后边的数据处理EIS裁切后的数据，既能够提升后续算法的稳定性，也能够减少后续算法的运算量，降低功耗。
            3. 不足：预览流和录像流没有解耦，导致无法启用视频缓存帧的功能，但目前该问题在天机2000的新的框架中可以得到解决
        3. 预研MTK-EIS 5.0
            1. 原因：
                - 相较VIDHANCE-EIS，MTK-EIS的运动模糊会减弱
                - 相较于去年3.5的版本，其升级了算法库，提升了防抖稳定性，增加了对OIS的支持
            2. 评估流程
                1. 软件集成导通（已完成）
                2. 第一轮画质评估（已完成）
                   - 相较于VIDHANCE-EIS，其运动模糊有改善，但是其防抖稳定性稍弱
                3. 第二轮画质评估（待双方完成进一步的校准优化，再进行评估）
        4. 完成SelfEIS在MTK平台的适配
            - 尚未进版，待算法组评估效果
    2. [K9][Qcom]平台
        1. 录像场景下功耗高的问题，配合三方完成模块拆解，对pipeline进行裁剪
        2. 完成SelfieEIS的适配工作，最终因为功耗表现较差，没有正式合入
2. 运动跟拍算法集成相关
    1. [K10/K10A/K11R][MTK]平台
        - 完成对VIDHANCE-WPE版本的usefullfov功能的适配，以此来保证tracker的跟踪框比例为16:9
    2. [K9][Qcom]平台
        - 定位解决GPU型号修改导致运动跟拍功能失效的问题，最终通过高通更新SNPE来解决
3. 其他问题的解决和代码提交：
    1. Jira - close了130个问题（不包含任务类Jira），主要包括录像相关的问题
    2. Gerrit - 提交了120笔代码

内功
1. 整理了录像场景下数据流的input & output的size，尤其是eis开启margin时候的size，方便在K10、K10A、K11R等项目中拉齐
2. 整理整合了MTK平台的dump&log的关键字和开启命令，提升了分析问题时候的效率
3. 整理EIS算法遇到的问题，进行归类总结，提升了对所遇到的问题的认知深度以及对一些接口的理解程度

工作总结
1. 目前工作内容主要集中在streaming流，对capture流以及相关的算法上移框架了解的都比较浅，后续需要逐渐补足对capture相关知识点的认知，并去探索将拍照上面的相关特性和功能复用到streaming流的可能性
2. 针对EIS算法，侧重于对功能的打通以及集成的稳定性的验证，对一些关联性问题（运动模糊，视频降噪）了解的不够，解决效果相关的问题时候思路还是比较寨，后续需要更多地关心tuning的一些参数配置，来更好地与eis进行配合
3. 目前对框架的整体性把握不够，后续应当更加注重阶段性的总结，加强对知识点的整理归纳

- EIS相关(独立负责)
    - 参与的相关项目：J10,K9,K10,K10A,K11R,L0A,L11,L11A(同时包含Qcom & MTK)
    - EIS算法包含三类，共四套代码：Qcom-EIS, MTK-EIS, Vidhance-EIS(basedon-Qcom、basedon-MTK)
    - 算法包含多个子类：超级防抖功能，水平矫正功能，自拍防抖功能，EIS-LDC功能
    - 新功能
        - EIS+OIS
            - MTK平台首次使用OIS，也是EIS+OIS方案在MTK平台的首次落地。
            - 前期参与并完成了基于K10A样机的预研工作并顺利通过评估，目前已经在L11顺利导通
            - 该功能对MTK旗舰机型上Video的综合成像表现有较大提升。
        - SelfEIS
            - 在K9上开始预研评估，目前顺利在L11上落地
    - 功耗&性能优化：
        - 主导完成eis在wpe模块上的集成工作，顺利在K10及后续的MTK项目上落地，节约>30ma，4k录像场景优化了接近80ma
        - 主导完成eis的sensor数据(包括gyro，ois，acc等)获取方式的迁移，由Android标准接口转换为SensorProvider，消除跨进程通信，预期可改善功耗表现
        - 主导完成Inline-WPE的适配：
            - 利用ISP7的新接口，主导完成了inline-wpe的适配
            - 相较于旧的wpe接口，能够少串一个vmdp节点，从而简化flow逻辑，提升性能表现。
        - 主导完成Pre-Tpi的适配：
            - 为改善高解析力场景下EIS的跟手性，针对4k场景，让EIS运行在最前一个节点，从而降低内存和性能开销，提升跟手性
    - 完成多轮效果评估工作：
        - mtk-eis 3.0 vs vidhance-EIS G3
        - mtk-eis 5.0 vs vidhance-EIS G4
    - 配合完成多次功耗评估工作
        - 针对K9超级防抖功耗过高问题，与三方&Qcom一起进行周期一个月的功耗拆解
        - 自拍防抖预研时，协助完成功耗评估工作
        - eis-margin功能上线时，配合完成前期的功耗摸底
        - mtk-eis 3.0 vs vidhance-EIS G3 的评估工作中，包含了功耗对比，期间拆解发现多个问题(DSDN,录像计时,屏幕刷新率不稳定)，为后续K10的录像功耗优化做了一定贡献
- 运动跟拍(独立负责)
    - 参与的相关项目：J10,K9,K10,K10A,K11R
    - EIS+Tracker算法的联合使用
    - 为改善用户体验
        - 优化了框图的size和裁切的逻辑，在平台flow差异无法克服的情况下，维持了效果的一致性
- 电影模式(独立负责)
    - 在mtk的isp6s上，将电影模式放置到Vmdp节点完成
    - 在mtk的isp7上面，考虑到vmdp在受wpe的影响不再使能，完成其向helperNode的迁移
- 其他：
    - 完成对eis的基础知识总结，并对应届毕业生进行eis的相关分享
    - 完成两篇EIS相关专利的撰写和提交
    - 对自己所学进行总结，并汇总了二十多篇wiki
    - 进入项目一年多，共处理包含算法集成和相机稳定性在内的共350多个bug，合入了近200个提交
    - 为方便评估工作对项目功耗数据进行总结与对比
    - 为方便问题定位，对多个项目中，相机数据流中的imageSize进行总结与对比
    - 为提升工作效率，对mtk & qcom 平台的dump&Log进行整合

马滔同学自入职以来，便积极学习思考，不断总结，先后输出了20多篇学习心得，并对组内的应届大学生进行了电子防抖的相关培训；独立承担了包括电子防抖，运动跟拍和电影模式在内的三个算法的软件适配工作，是深圳区域相机视频模块的核心负责人，共解决了350多个问题，提交合入了200多个修改，先后共完成了八个项目的顺利交付；勇于创新，通过工作中的积累与思考，完成了两个专利的审核提交。

在项目适配过程中，积极思考并完善防抖算法在功耗，性能等多维度的表现。在改善录像场景功耗方面，主动与平台厂商对接，完成了算法硬件处理模块从GPU至WPE的切换，针对不同的分辨率场景，对功耗有30-80mA的优化。在提升算法性能方面，积极与平台厂商沟通，主导导通多条全新的接口通路，最终实现了算法处理时间耗时降低40%，显著改善了高分辨率场景下录像跟手性差的问题。在平台的首次光学防抖的适配工作方面，积极联通电子防抖和光学防抖，优化数据传输途径，在不影响性能的前提下充分发挥光学防抖的作用，使得Video的综合成像表现有较大提升。
在K10项目中，封包前一天测试上报严重的录像色彩问题，便立即分析排查，依靠前期经验和知识积累，快速定位到问题所在的模块，并积极与平台厂商沟通正面解决方案的。鉴于问题紧迫性，积极沟通准备备选方案以保证顺利封包。最终采用备选方案，顺利完成了封包，保证了项目的正常交付，得到了组内同事的一致好评。



本周工作（2022.03.14~2022.03.20）：
【L11】MATISSE-14794，录像模式下，杀掉相机进程后，重进相机，系统提示“无法连接相机”。分析是在美颜场景下将美颜强度调至最高，出现hang的问题，已经交由对应同事进一步分析
【L11】MATISSE-11200，后摄Video- feature-短视频、VLOG、电影镜头、萌拍、魔法分身与普通录像亮度表现不一致，分析是由于客制化BT709时候，将PQDIP的inputpot设为BT709，导致之前阶段flow中的数据均为BT709，从而导致亮度差异，目前将其修改为BT601_full可解决该问题，待合入正式patch
针对录像结束时候有卡顿的问题进一步debug分析，发现是warpMap pool较小，导致的delay，配合验证mtk-eis可以解决，但是针对tpi-eis，提升不明显，需进一步debug
参加DX-2会议，参与讨论后续新feature的研发规划

下周工作（2022.03.21~2022.03.）：
进一步跟进L11上Video的相关问题
解决L11 & L11A相关jira

## 评价他人
海波：
1.2022年上半年完成L11\L11A、L2M、L12A 后置Video全模块测试，已上市的项目整体反馈较好；
2.在人力紧缺和项目周期极短的双重压力下，高质量完成项目后置Video画质评测工作（L2M）
3.持续迭代Video评测场景和case，新增实验室、办公室暗室、来福士商场等场景；应对卖点和新功能需求，制定夜景视频、HDR10+评测方法和case。
4.完成MTK平台首次增加的夜景视频、HDR10+ 等Feature的画质评测工作，并且在L11上夜景视频效果优于同期对比机。

1.坚持在项目后输出遗留问题&疑难问题总结，并拉通调试、软件、算法，对后续项目画质进行良性迭代；
2.已完成21届毕业生培训，两位同学都能独立承接Video画质评测工作；正在准备22届毕业生的培训。
3.规划人力和项目任务平衡，使得在现有人力上能并行承接多个项目Video评测工作。
4.根据用户使用场景频率和场景占比权重，修改优化Video主观画质评审case。并协助杨斌完成深圳区域主观画质评审。

A:
- 海波对待工作责任心非常强，video作为一个复杂的模块，他能够在项目多，时间紧的条件下，保证好项目的交付，在他的督促下，才有了深圳相关项目video交付的低用户反馈率
- 针对测试过程中的一些细节，能够不断学习，不断拓宽，进一步细化一些测试场景，测试流程，报错提出的问题有依据，可量化
- 日常中的沟通也很顺畅，能够始终以项目交付为前提，主动沟通，主动协商，针对一些影响较弱的问题，也能做出主动让步，大大缓解研发的压力
B:
目前测试周期还是相对较长的，希望后续针对video的相关测试流程和场景，能够更加固定，不断改进，争取也能够达到自动化

新成
1. 完成L11，L11A项目上前置bokeh，videobokeh和videofilter的功能交付，未造成项目delay。
2. 主要解决L11/L11A上videobokeh基于标定数据计算没有效果问题。
    2.1 工厂标定后的工序造成手机模组偏移，与标定数据不匹配。
    2.2 videobokeh算法cover的标定数据与模组的偏移范围有限。
    2.3 统计P2及后续产线上手机标定数据与模组的偏移，为videobokeh算法添加一个固定偏移，cover住产线整体标定数据偏移。

1. 完成L2M项目上前置bokeh，videobokeh和videofilter的功能交付，未造成项目delay。
2. 解决L2M上videobokeh在发生手机模组与标定数据存在偏移导致没有效果问题，优化learning机制。
    2.1 将L2Mvideobokeh方案与L11/L11A进行区分。
    2.2 添加在线learing方案，在刷机后第一次进入videobokeh就开始learning，并使用Learning结果计算bokeh效果。
3. 预研mtk平台单摄后置videobokeh，提供备选方案。
    3.1 预研mtk平台上小米自研算法和虹软算法，进行对比。
    3.2 小米自研算法采用depth计算与bokeh计算分开的方式实现，设计通过meta传输depth。

内功
1. 总结mtk7s平台后置双摄videobokeh方案实现文档，总结常见问题分析方法。
2. 预研单摄后置videobokeh方案，提供多种方案选择，总结单摄方案集成设计。

A:
新成对待工作责任心非常强，针对项目的交付工作，一直在竭力做到最好。之前的L11项目中虚化效果异常的问题，勇于承担，主动拉通相关人员，前前后后跟了近两个月，最终达到了交付目标，没有影响封包
在工作中也在不断思考和总结，针对之前双摄虚化的问题，为了避免后续还有相关问题，他主动争取并承接了单摄虚化的任务，为项目交付提供了进一步的保障

B:
在日常的沟通中还相对腼腆，以后能够更加积极主动，扩大自己的个人影响力

庆轩：
1. 项目交付
[xTS交付工作]作为深圳相机软件xTS接口人，上半年Q1季度主要负责了L11/L11A封包及OTA送测，Q2季度负责了L2M/L12A/L12/L12U首包IR送测。具体负责了两个平台CTS问题和因人员变动临时承接了高通平台的ITS工作。其中L2M/L12A/L12/L12U时间节点有冲突，但依然保证了项目高质量交付，期间没有因为Camera模块引起重打包delay项目，JIRA解决率100%。
2. 风险防控
[xTS风险防控]堵不如控，为了减少项目交付风险，缓解紧张的人力，从多方面对xTS交付风险进行了防控，改善了相关工作方法。
- 制定流程，考虑到开发管控底线和测试成本，参与重新制定了xTS测试流程，从流程上减少发生重打包delay项目发版等重大风险。
- 管控节点，同组内项目经理沟通，对重要节点前的Patch进行管控，Camera Patch通过Verify xTS测试后才可进版；通过开发patch检测工具进行漏合检测，及时提醒；关键节点前同PM沟通，发起Camera xTS特殊测试申请。
- 自主监控，目前开发人员负责对开发版日监控，测试不再负责，监控开发版可及时发现并处理问题，避免合入稳定版。
- 代码评估，关键节点前涉及到一些风险的patch，进行部分模块自测。
- 提前摸底，Q2季度对于Android T CDD新要求进行摸底，T上风险点主要在于MTK和高通平台对新增三方开放bokeh，night功能的Extension技术不支持，需要提前学习实现，并且T版本首次要求打开多摄测试。目前北京同事和谷歌沟通后在T上暂时取消对三方开放一些能力的要求。关于多摄问题提前在MTK S平台上开启自测，风险可控。
3. 效率创新
[压测自动化分析工具优化]
作为该项目的开发人员，在2022年Q1和Q2季度维护了该工具的正常运行和升级工作，保障了深圳稳定性的顺利进行。
- Q1季度主要优化了现行工具的分析速度，提高分析效率80%左右，减少压测及MTBF问题分析周期，加快了推理工具的落地。
- Q2季度项目间歇期间重构了该工具的框架，目的为了统一推理和关键字解析两种功能，并提高程序的可维护性，扩展性，分析结果的可读性，为兼容其他分析工作做准备。目前编写了设计文档，现阶段完成了框架和部分模块的开发。

内功
1. 工作方法提升及技术沉淀
- 规范流程，提前评估:
作为xTS的接口人，为了保证项目顺利交付，合理调整了防控xts交付风险的工作方式，提前进行下一个版本的认证风险进行评估和学习。
- 进行技术总结:
这半年主要对ts问题分类和权限问题进行了整理，输出为飞书文档，其中包括CTS问题分类及历史问题汇总1篇，Android S ITS Case解析1篇，Android T CDD评估1篇，VNDK及Selinux权限4篇，Android 库链接器启动流程1篇，各类内存问题在ASAN和HWASAN工具上的区别1篇，初探编译原理1篇。
- 提高效率: 开发效率工具，攥写相关文档，为组内提高解决问题的效率。
- 提案专利一篇

2. 体系建设贡献
- 带xTS相关人员1人
- 驱动组内技术分享一次

A:
- 庆轩在自己的工作岗位完成得十分出色，xTS的相关问题本身的根因会比较复杂，涉及到的模块多且杂，庆轩通过自己扎实的代码能力，对不同模块，仓库都能有一定的了解，能够在短时间内解决相关问题，保证项目的正常交付
- 在完成自身工作的基础上，也在不断思考和尝试。首先，针对xTS提出新的管控方案，能够大大改善效率，减少人力；其次，凭借自己的python的扎实基础，完成自动化工具的开发，大大提升了团队的工作效率
- 不断总结创新，自己工作的基础上，还能提出新想法，并凝练出专利
B:
目前的工作内容比较杂，且需要cover的范围也广，需要提升对某一模块的专注度，把更多时间花在那个模块上

永刚：
1.负责MTK DX-1平台上的L11和L11A项目上集成极感公司的超广角畸变矫正算法，该极感公司的算法是首次在MTK平台上落地，因是首次在MTK平台上集成，并且该三方算法还在开发中，没有现成可以用的代码，需要自己编写，同时也遇到了开发新功能(专业模式RAW拍照支持畸变矫正)、crash、selinux权限、效果、性能等等很多问题，最后都解决了，成功交付了。为后续项目继续使用极感公司的超广角畸变矫正算法积累了项目经验。

2.负责MTK DX-1平台上的L11和L11A项目上集成三方美颜算法，因是MTK的新平台，在该平台上遇到crash、效果、性能问题，再加上该算法有缓存帧和仅用CPU处理等缺陷，进一步增加了集成该算法时的难度，最终都解决了，成功交付了。

3.负责MTK DX-1平台上的L2M和L12A项目上集成altek公司的AI+LDC算法，因该项目时间周期仅仅只有1.5个月的时间，同时AI用的是altek公司自己的，这种AI+LDC的组合是首次在MTK上用，并且altek公司的AI+LDC的组合以前从来没有在该MTK上用过，我们的L2M和L12A项目是第一使用，在集成的过程遇到了开发新功能、crash、绿屏、效果、性能等很多问题，最后都解决了，成功交付了。为后续项目继续使用altek公司的自带的AI+LDC算法积累了项目经验。

4.负责MTK DX-1平台上的L2M和L12A项目上集成三方美颜算法，在该平台上遇到了开发新功能(美妆)、crash、效果、性能等等很多问题，最终都解决了，成功交付了。

5.负责高通8475平台的L12项目上集成altek公司的AI+LDC算法，因该项目时间周期仅仅只有2个月的时间，同时AI用的是altek公司自己的，这种AI+LDC的组合是首次在高通上用，并且altek公司的AI+LDC的组合以前从来没有在该MTK上用过，在集成的过程遇到了很多问题，最终都解决了，正在交付的最后阶段。

6.负责高通8475平台的L12项目上集成三方美颜算法，在该平台上遇到了上新的MIVI架构引出来的一些问题，目前正在解决中。

内功
1.MTK DX-1平台上的L11和L11A项目后期要求，在专业模式下拍RAW照，要支持拍出来的超广角JPG照片带有畸变矫正功能。接到任务后想了两套方案，一套方案让raw拍照产生的一张YUV图片过算法上移框架，在算法上移框架里做畸变矫正，另一套方案是让raw拍照产生的一张YUV图片在底层的camerahalserver做畸变矫正，在camerahalserver层需要实现一套和算法框架一样的畸变矫正功能。第一种方案的实现需要app应用参与，而第二种方案不需要应用参与，最终考虑到时间以及应用的配合度的情况，选择了第二种方案，实现了camerahalserver下的畸变矫正拍照代码，实现后遇到了超广角raw拍照crash、专业模式下调节快门拍照畸变等等问题，最终都都一一解决。该功能成功开发后，增强了用户体验，后续的L2M和L12A产品都上了该功能。

2.L2M项目时间周期仅仅只有1.5个月，要在L2M和L12A项目上集成altek公司的AI+LDC算法，该AI+LDC算法也是ALTEK第一次在MTK平台上集成，并且该三方算法还在开发中，同时开发时间短加上新方案本身不成熟以及需要适配所有场景的情况，这就导致AI+LDC算法上到L2M项目上存在非常大的风险。在开发的过程中，遇到了由于该算法在拍照时耗时比较长的问题，为了支持连拍，又添加了一套快速矫正算法AHLDC，相当于一个超广角拍照同时加载运行两套算法，增加了开发的难度、内存以及稳定性的风险。在做该功能时做了可行性分析，做好后又做了内存占用是否超标的测试以及稳定性的验证，在项目后期遇到小概率三方算法加载之前生成的bin shader报错导致拍照绿屏问题，反馈问题给三方，三方没思路也没进展，他们也觉得小概率问题，不是自己的代码问题等等。提CR给MTK，MTK按照GPU问题进行分析，天天抓日志也毫无进展， 眼看要接近封包时间，意识到这个问题的严重性。就自己花时间分析和研究这个问题，并要求三方贴出出错的代码截图，自己模拟三方的方法写demo复现该问题，分析出错的shader bin文件，分析三方代码的缺陷，测试验证问题，随着对问题的不断深入的研究和分析，得出1.出问题的bin文件和正常的文件有些不同，而且该问题出现在升级ROM时没清理userdata会很容易出现，这个原因是新的ROM里有对GPU相关改动，导致对原有的bin文件不再支持。2.通过对加载错误的bin文件，再重新编译一遍即可解决该问题。带着这个结论和三方沟通，三方按照此方法解决了该问题。在解决这个问题时也遇到了三方为了减少初始化时间，采用谷歌通用的AI框架开发，用新方法并没达到理想的耗时，三方分析了多天也是毫无进展，分析问题也不够积极，于是也是和方一起分析该问题，最终解决了该问题。后期也遇到了一些crash的问题，最终都解决了。通过这次开发总结出:1.并不是所有的三方公司都那么积极去解决问题，需要我们去督促他们去解决。2.我们做的项目更多，对自己负责的项目会更了解，遇到问题要多三方沟通交流，对问题进行深入的了解，说不定我们也能提出更好的解决方案。3.项目周期太短尽量不要上三方还在开发的算法，不然会在开发的过程中出现很多问题，如果解决不及时很可能会影响项目封包。

3.在L2M上收到一个快拍的bug，该bug是快拍时开启美颜算法后，快拍8张后出现卡3~5秒才能进行下一次拍照，分析后，发现是美颜耗处理一帧耗时比较久，导致无法进行持续的快拍，和三方美颜算法公司沟通，三方公司也没有很好的解决方案，来回沟通很多次都没有结果。意识到这是个很棘手的问题，在沟通的同时，也把这个问题反馈给了刘杰主管，在刘杰主管的指导和帮助下对该问题进行分析和解决，拆解耗CPU资源比较的多的线程如图库、MCN、arcsoft预览等等耗CPU资源比较多，看看这些线程能否优化减少耗用CPU资源，尝试提高算法优先级，美颜绑定四个大核运行，拍照时降低预览帧率等等方法。虽然有改善但是还是无法解决快拍8张后出现卡3~5秒问题。对日志进一步分析，发现美颜快拍时每处理一帧需要600ms ~ 1000ms  ，如果代码优化好的话应该可以做到前几张快拍，后面可以匀速拍照，匀速时间可以做到和美颜处理一帧的时间一致，拍照时间间隔也在600ms~800ms之间，这样就不会出现卡3~5秒问题，带着这个想法开始对整个快拍架构进行研究，和刘杰主管一起讨论如何从架构层面进行优化，在hal层和app层做尝试，发现通过对app代码做少量的修改可以解决此问题。最终在刘杰主管的知道和帮助以及推动下，应用解决了该问题。通过对这次问题的解决可体会到有些问题虽然看似无法解决，实际上可以多想些办法，还是能够想出很好的优化方法的。当然这要花费大量的时间，要在短时间内阅读很多代码，要想很多去解决该问题的方法，还需要领导的全力帮助、支持和指导。

4.在开发L11项目时收到一个bug是，前摄开启美颜拍照后立即QuickView时，有fov有压缩感，通过对问题分析以及查阅代码发现，这个问题与美颜无关，是由于sensor出图不是4:3，但是预览图会被裁剪成4:3，而拍照又不做4:3裁剪。虽然这个问题与美颜无关，但是还是想着把这个问题解决了。  当时正处在封包阶段，驱动的修改sensor出图为4:3影响比较大，经过分析应用收图时再裁剪为4:3的尺寸影响最小，但是应用说他们都是公司统一代码不会为我们这个项目做修改。找MTK的F1想办法，F1说快封包了，这个问题现在才报出来，有些晚，他建议我们改预览的代码，但他也不知道如何改。对预览代码进行了一番研究，发现改预览代码影响太大了，想着能不能让应用下4:3尺寸的图，然后google支持的尺寸添加了一项支持4:3尺寸的数据，这样hal层在处理完的走后阶段会把非4:3尺寸的图裁剪为4:3比例，试验有效，因这样的修改可能会影响CTS和XTS，在进开发版前测试CTS和XTS都不影响，通过这样修改解决了改问题。后来无意间用公司高通的L3机器测试前摄拍照，发现该机器QuickView存在压缩感，当时看到这一幕感觉自己小有成就。通过对这个问题的处理，让自己处理问题的能力又有了一次不小的提高。

5.在这一段时间也遇到了很多其他的问题，这些问题的解决让自己的能力有了很大的提高。

A:
- 对待工作非常得有责任心，有耐心；针对项目中的每个问题，都能做到弄会，弄透，绝不会轻易放过任何一个bug，坚持找到问题的rootCause，在此过程中经常加班加点，解决了诸多平台&算法&适配上面的疑难杂症
- 工作能力突出；上半年中并行多个项目且是两个平台并行，凭借出色的代码能力，他在很短的周期内保质保量地完成多个全新算法方案的适配，同时完成美颜 & LDC两个重要算法的工作，覆盖了streaming & capture & 算法上移等多个flow，均十分出色地完成，是团队的中坚力量
- 做事扎实，勤恳；作为算法交付，他不单单简单地做适配，还会从内存，性能，power得多个问题去思考、改善算法，每件事做小，做细
B:
工作过程中过于谦和，对很多问题的处理也比较温和，需要后续能够更加坚定地push兄弟团队协助解决问题
