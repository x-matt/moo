1. ==图像分类、数据驱动方法和流程==
2. ==Nearest Neighbor分类器==
3. ==k-Nearest Neighbor== _译者注：上篇翻译截止处_
4. ==验证集、交叉验证集和超参数调参==
5. ==Nearest Neighbor的优劣==
6. ==小结==
7. ==小结：应用kNN实践==
8. ==拓展阅读== 10. 图像是3维数组，数组元素是取值范围从0到255的整数。数组的尺寸是宽度x高度x3，其中这个3代表的是红、绿和蓝3个颜色通道。
11. 给计算机很多数据，然后实现学习算法，让计算机学习到每个类的外形。这种方法，就是数据驱动方法。
12. 图像分类流程 **输入****(**N个图像训练集和K种分类) **学习**(训练分类器) **评价**（评价分类器的质量）
13. **先找最相似的一张图片，通过像素距离差值，比较相似率** **NN**
14. **找多张相似的图片作为标签，即为****KNN**
15. 超参数(hyperparameter) K取多少，用L1范数还是用L2范数从属于超参数
    
    - L1是绝对值最小，L2是平方最小：
    - L1会趋向于产生少量的特征，而其他的特征都是0，而L2会选择更多的特征，这些特征都会接近于0。
    - L1比L2更容易得到稀疏解(用更少的变量表示一个值) 17. **过拟合**：==使用测试集进行训练时，算法实际部署后，性能可能会远低于预期。这种情况，称之为算法对测试集====过拟合是：模型训练时候的误差很小，但是测试误差很大，也就是说模型复杂到可以拟合到所有训练数据，但在预测新的数据的时候，结果很差。==
18. 从训练集中取出一部分数据用来调优，我们称之为**验证集（validation set）**
19. 把训练集分成训练集和验证集。使用验证集来对所有超参数调优。最后只在测试集上跑一次并报告结果。 #critical
20. 交叉验证 训练集的数量较小，分成几等份，每次取其中一份位验证集，最后取多次结果的平均值。 
## 优劣：

NN算法不需要训练，但测试花的时间较多，我们需要把时间关注在测试时间上，即应用时候很快。（卷积神经网络即为如此）ANN可以帮助NN在 准确率 和 时空复杂度上做出平衡，依赖预处理过程，包含kd树和k-means算法
 25. **该方法只是在比较像素，基于图片的背景**
26. **分类器必须记住所有训练数据并将其存储起来，以便于未来测试数据用于比较。这在存储空间上是低效的，数据集的大小很容易就以GB计。**
27. **对一个测试图像进行分类需要和所有训练图像作比较，算法计算资源耗费高。**
28. **normalize** **是排除数值大的特征分量产生主导影响，****zero mean****和****unit variance****主要是为了让数据符合标准正态分布**        
## 优劣：