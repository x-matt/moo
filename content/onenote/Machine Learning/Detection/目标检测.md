# 检测概述

- # 检测概述
    
    1. 分类
    
    关心整体，对整张图片的描述
    
      
    4. 检测
    
    前景和背景  
    目标描述（位置、类别）
    
      
    7. 分割（适用于理解要求较高的场景）
        
        1. 语义分割：对前背景分离的拓展(semantic) 分类的进一步拓展
        2. 实例分割：检测任务的拓展，描述出目标的轮廓(instance) 对box的进一步逼近
![Exported image](Exported%20image%2020240403195652-0.png)  
- # 2-Stage 检测模型（基于区域）
    
    1. R-CNN
        
        1. 流程：输入 -> 提取RP-> CNN提取feature map -> 分类
        2. 从图像提取出若干个可能包含物体的区域（region proposal）:局部裁剪：selective search算法
        3. 使用分类网络（AlexNet）
        
        - 数据的准备 IoU 描述区域重合程度 正样本（>0.5）和负样本(<0.1) 两者之间的叫 hard negatives
        - 位置坐标的回归（bounding box regression） 加入log/exp函数使损失保持，也叫 normalization
        
        - 需要训练三个模型；重复计算；
        - 耗时：CNN在每个proposal上独立运行计算
      
    3. Fast R-CNN：共享卷积运算
        
        1. 流程：
            
            1. CNN提取feature map && 利用SS算法得出Rol（region of interest）
            2. 将ROI映射在FeatureMap上
            3. ROI pooling；输出为 ==等长==的 FeatureVector
            4. 正负样本整理
            5. 同时分类和回归（全连接层）
        2. ROI Pooling的作用：
            
            1. 为每个ROI选取对应的特征
            2. 为了满足全连接层的输入需求
            3. 输出一样大小的特征（归一化）
    
    改善了串行提取方式，ss之后用一个神经网络进行特征提取
    
      
    6. Faster R-CNN：两阶段模型的深度化（取代ss）
        
        - RPN网络取代selective search，检测可以端到端完成（全部可以自己学习）
        - Region proposal networks 转化为二分类问题（是否为物体）
        - 基于feature map进行anchorbox的计算 [https://blog.csdn.net/qian99/article/details/79942591](https://blog.csdn.net/qian99/article/details/79942591)
        - RPN作用：增加 ROI_Size 的多样化（将SS算法与Sliding Window 结合）
            
            1. 判断anchor是前景还是背景
            2. 为属于前景的anchor进行第一次修正
            3. IOU值为0.7以上，则为前景(positive)，在0.3以下则为背景(negative)
                
                1. 首先通过RPN生成约20000个 anchor （ 40 × 60 × 9) 。
                2. 对20000个anchor判断前后景--Softmaxloss（分类）
                3. 前景进行第一次坐标修正，得到修订边框后的 proposal 。--SmoothL1 loss （回归）
                    
                    1. 先做平移（dx、dy）
                    2. 再做缩放（dw、dh）
                    3. 通过线性回归 Y=WX 实现四个参数的确定 [https://blog.csdn.net/elaine_bao/article/details/60469036](https://blog.csdn.net/elaine_bao/article/details/60469036)
                4. 映射回原图，忽略掉长或者宽太小的 proposal。
                5. 将所有 proposal 按照前景分数从高到低排序 ， 选取前12000个 proposal。
                6. 使厍阈值为0.7的NMS（非极大值抑制）-局部最大值-算法排除掉重叠的 proposal
                7. 针对上一步剩下的 proposal ，选取前2000个proposal 进行分类和第二次边框修正 。
    7. Mask R-CNN -- 分割
        
        - 在faster r-cnn加了mask prediction branch(改了loss function) 回归
        - 全卷积网络
        - 输出：k类的mask（sigmoid函数），与0.5比较输出二值mask
        - head的作用：将RoI Align的输出维度扩大
        - 改良了ROI Pooling->ROI Align 不再取整，采用双线性插值（Bilinear interpolation）
            
            - ![clip_image001](Exported%20image%2020240403195652-1.png)
            
            - ![(12 — — yı) (12 — — yı) ) ( yry) (12 — — yı) (12 — — yı) ](Exported%20image%2020240403195652-2.png)
          
        ![Exported image](Exported%20image%2020240403195652-3.jpeg)- 先插值，再max pooling
        - FCN与CNN的区别在于把CNN最后的全连接层换成卷积层（全卷积层）
        
        -   
            
- # 1-Stage Region-Free（全局处理）
    
    1. YOLOv1（you only look once）- 无法分割
        
        1. 优点
            
            1. 速度快
            2. 背景错误相对较少
            3. 泛化性好
        2. 每个bounding box有5个回归值：四个表示位置（x,y,w,h），一个表示置信度-confidence
        3. 每个cell包含B个box和C个类别：location（8维）+confidence（2维）+clasification（20维）
        4. 详解过程
            
            1. S*S个cell -> 输出：S*S*（5*B+C）
            2. confidence=是否有物体*预测有多准
            3. 每个网格预测的类别信息*confidence
            4. 设置阈值，滤掉分低的box，剩下的进行NMS处理
        5. 不足
            
            1. 每个格子只能预测一个物体，即便包含多个物体，也只能检测出其中一个
            2. 对相互靠近的物体，很小的群体检测效果不好
            3. 泛化能力偏弱，对不常见的长宽比检测效果不好
            4. 定位误差影响较大，尤其是处理大小物体上
    2. YOLOv2
        
        1. 目的：提高准确度
        2. 改进：
            
            1. Batch Normalization：提高收敛性，消除对正则化的依赖
            2. High resolution classifier：224*224->448*448
            3. Convolution with anchor boxes：用anchor预测bounding boxes
            4. 多尺度训练
            5. worldtree混合ImageNet（分类）和COCO（位置）
    3. YOLOv3
        
        1. 改进：
            
            1. 多尺度预测--感受野小的适合检测小尺寸对象--32倍，16倍，8倍下采样
            2. 更好的基础分类网络ResNet和分类器darknet-53
            3. 分类器-类别预测
            4. 9个anchor
          
        
    4. SSD（single shot multibox detector）
    5. FPN（多尺度检测） 在不同的尺度进行独立的预测/上采样
    6. RetinaNet + Focal Loss
    
    - 基础网络：特征提取器，给出图像不同大小，不同层次的抽象表示
    - 检测头部：将表示与监督学习类别和位置相关联（类别预测&位置回归）
    
# 2-Stage 检测模型（基于区域）

特点  
缺点：
      

[https://blog.csdn.net/jiongnima/article/details/79094159](https://blog.csdn.net/jiongnima/article/details/79094159)
 
![[Mask R-CNN.pdf]]